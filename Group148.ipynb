{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Assessment 1\n",
    "# FIT5196 Task  in Assessment 1\n",
    "#### Student Name: Pattranit Chaiyabud and Viet Tai Le\n",
    "#### Student ID: 30304148 and 29975336 \n",
    "\n",
    "Date: 22/08/2019\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3.6.0 and Anaconda 4.3.0 (64-bit)\n",
    "\n",
    "Libraries used:\n",
    "* pandas (for dataframe, included in Anaconda Python 3.6.0) \n",
    "* re (for regular expression, included in Anaconda Python 3.6.0)\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "This assignment comprises the execution of different text processing and analysis tasks applied to patent documents in XML format. There are a total of 150 patents in the file named `Group148.txt`. The required tasks are the following:\n",
    "\n",
    "Extracting data from semi-structured text files. Based on the data-set that contains information about\n",
    "grants given for IP patent claims . The data-set contains information about several patent grants, e.g.,\n",
    "patent title, patent ID, citation network, abstract etc. Our task is to extract\n",
    "the data and transform the data into the CSV and JSON format with the following elements:\n",
    "1. grant_id: a unique ID for a patent grant consisting of alphanumeric characters.\n",
    "2. patent_kind: a category to which the patent grant belongs.\n",
    "3. patent_title: a title given by the inventor to the patent claim.\n",
    "4. number_of_claims: an integer denoting the number of claims for a given grant.\n",
    "5. citations_examiner_count: an integer denoting the number of citations made by the\n",
    "examiner for a given patent grant (0 if None)\n",
    "6. citations_applicant_count: an integer denoting the number of citations made by the\n",
    "applicant for a given patent grant (0 if None)\n",
    "7. inventors: a list of the patent inventors’ names ([NA] if the value is Null).\n",
    "8. claims_text: a list of claim texts for the different patent claims ([NA] if the value is Null).\n",
    "9. abstract: the patent abstract text (‘NA’ if the value is Null)\n",
    "More details for each task will be given in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examining and loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, the file `Group148.txt` will be loaded so its first 10 lines can be inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<us-patent-grant lang=\"EN\" dtd-version=\"v4.5 2014-04-03\" file=\"US10362598-20190723.XML\" status=\"PRODUCTION\" id=\"us-patent-grant\" country=\"US\" date-produced=\"20190709\" date-publ=\"20190723\">\n",
      "<us-bibliographic-data-grant>\n",
      "<publication-reference>\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>10362598</doc-number>\n",
      "<kind>B2</kind>\n",
      "<date>20190723</date>\n",
      "</document-id>\n"
     ]
    }
   ],
   "source": [
    "# print first ten lines of the file\n",
    "with open('Group148.txt','r',encoding=\"utf-8\") as infile:\n",
    "    print('\\n'.join([infile.readline().strip() for i in range(0, 10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each patent start from tag `<?xml...?>` and root tag `<us-patent-grant>` and end with the closing tag `</us-patent-grant>` . So to get list of all patent we use re.findall with regex `r'<\\?xml[\\s\\S]*?</us-patent-grant>'` .\n",
    "The non-greedy pattern `*?` is necessary so the whole file is not matched. The regex also uses the pattern `[\\s\\S]` (white space or non white space characters) which causes to capture everything, even line breaks, between the XML declaration and the closing tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read a whole file and put data in a list that contains information of each patent\n",
    "with open('Group148.txt','r',encoding=\"utf-8\") as infile:\n",
    "    fileline = infile.read()    \n",
    "regex = r'<\\?xml[\\s\\S]*?</us-patent-grant>' \n",
    "patents = re.findall(regex, fileline)\n",
    "# patents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parsing Raw Text Files \n",
    " Our approach is extracting 9 elements of a sample patent and then using for loop to extracting all patents.\n",
    " \n",
    " In order to transfrom data into csv file, we save extracted data in a data frame and using to_csv method of pandas library\n",
    " \n",
    " In order to saving data to json file, we try to write a text file in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a list contains processed data of patents\n",
    "data=[]\n",
    "#Initialize a dictionary \n",
    "dict1={}\n",
    "for i in range(len(patents)):\n",
    "    sample_row=patents[i]\n",
    "    #grant_id\n",
    "    grant_id=re.search(r'file=\"(.*?)-(.*?)\"\\sstatus',sample_row).group(1)\n",
    "    #finding title\n",
    "    p_title=re.search('<invention-title.*?>(.*?)</invention-title>',sample_row).group(1)\n",
    "    #number of claims\n",
    "    number_of_claims=re.search(r'<number-of-claims>(\\d*?)</number-of-claims>',sample_row).group(1)\n",
    "    #citations by applicant,examiner\n",
    "    number_cia=re.findall(r'<patcit[\\s\\S]*?</category>|<nplcit[\\s\\S]*?</category>',sample_row)\n",
    "    if len(number_cia)!=0:\n",
    "        # Initialize a variable for citation applicant count\n",
    "        applicant_count=0\n",
    "        # Initialize a variable for citation examiner count\n",
    "        examiner_count=0\n",
    "        for each in number_cia:\n",
    "            if 'cited by applicant' in each:\n",
    "                applicant_count+=1\n",
    "            elif 'cited by examiner'in each:\n",
    "                examiner_count+=1\n",
    "    else:\n",
    "        applicant_count=0\n",
    "        examiner_count=0\n",
    "    #inventors\n",
    "    list_inventors=[]\n",
    "    inventors=re.search(r'<inventors[\\s\\S]*?</inventors>',sample_row)\n",
    "    if inventors:\n",
    "        inventor_info=re.findall(r'<inventor[\\s\\S]*?</inventor>',inventors.group())\n",
    "        if len(inventor_info) != 0:\n",
    "            for each_inventor in inventor_info:     \n",
    "                inventor_lname=re.search(r\"<last-name>(.*?)</last-name>\",each_inventor).group(1)\n",
    "                inventor_fname=re.search(r\"<first-name>(.*?)</first-name>\",each_inventor).group(1)\n",
    "                inventor_name=inventor_lname + \" \" +inventor_fname\n",
    "                list_inventors.append(inventor_name)\n",
    "            inventors_str=re.sub(r'\\'|\\\"','',str(list_inventors))\n",
    "                \n",
    "        else:\n",
    "            list_inventors=\"NA\"\n",
    "    else:\n",
    "        list_inventors=\"NA\"\n",
    "    #kind\n",
    "    kind_grant=re.search(r'<publication-reference>([\\s\\S]*?)</publication-reference>',sample_row).group(1)\n",
    "    kind_info= re.search(r'<kind>([\\s\\S]*?)</kind>',kind_grant).group(1)\n",
    "    if kind_info=='B1':\n",
    "        kind='Utility Patent Grant (no pre-grant publication) issued on or after January 2, 2001.'\n",
    "    elif kind_info=='B2':\n",
    "        kind='Utility Patent Grant (with pre-grant publication) issued on or after January 2, 2001.'\n",
    "    elif kind_info=='E1':\n",
    "        kind='Reissue Patent'\n",
    "    elif kind_info=='P1':\n",
    "        kind='Plant Patent Grant issued prior to January 2, 2001'\n",
    "    elif kind_info=='P2':\n",
    "        kind='Plant Patent Grant (no pre-grant publication) issued on or after January 2, 2001.'\n",
    "    elif kind_info=='P3':\n",
    "        kind='Plant Patent Grant (with pre-grant publication) issued on or after January 2, 2001.'\n",
    "    elif kind_info=='S1':\n",
    "        kind='Design Patent'\n",
    "    #claim text\n",
    "    claims_info=re.findall(r'<claim\\sid=\".+\">([\\s\\S]+?)<\\/claims>',sample_row)\n",
    "    claims_text=re.sub(r'<[^>]*>|\\'|\\\"|\\\\n','',str(claims_info))\n",
    "    claims_text=re.sub(r'\\s{2,}','',claims_text)\n",
    "    if claims_text==[]:\n",
    "        claims_text=[\"NA\"]\n",
    "    #abstract\n",
    "    abstract=re.search(r'<abstract[\\s\\S]+?<p.+?>(.+)?<\\/p[\\s\\S]+?>',sample_row)\n",
    "    if abstract:\n",
    "        abstract=abstract.group(1)\n",
    "        abstract=re.sub(r'<.+?>|\\s{2,}','',abstract)\n",
    "    else:\n",
    "        abstract=\"NA\"\n",
    "    #for csv\n",
    "    data_row=[grant_id,p_title,kind,number_of_claims,inventors_str,applicant_count,examiner_count,claims_text,abstract]\n",
    "    data.append(data_row)\n",
    "    #for json\n",
    "    dict1[grant_id]={\"patent_title\":p_title,\"kind\":kind,\"number_of_claims\":int(number_of_claims),\"inventors\":inventors_str,\"citations_applicant_count\":applicant_count,\"citations_examiner_count\":examiner_count,\\\n",
    "                     \"claims_text\":claims_text,\"abstract\":abstract}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all elements in a patent, we using re.search method to extract each element \n",
    "### *Grant_Id:* \n",
    "The information about grant id located in tag <us-patent-grant..>\n",
    "\n",
    "for example: `<us-patent-grant lang=\"EN\" dtd-version=\"v4.5 2014-04-03\" file=\"US10362598-20190723.XML\" status=\"PRODUCTION\" id=\"us-patent-grant\" country=\"US\" date-produced=\"20190709\" date-publ=\"20190723\">`\n",
    "The id begin from `file=\"` and end before the next character `-`. Hence, we use regex: `r'file=\"(.*?)-(.*?)\"\\sstatus'` \n",
    ".The first group is the Id\n",
    "\n",
    "### *Patent_title:*\n",
    "The title information located between tag `<invention-title..>` and `</invention-title>`.\n",
    "\n",
    "for example: `<invention-title id=\"d2e53\">Method for relaying D2D link in wireless communication system and device for performing same</invention-title>`\n",
    "\n",
    "Similarly, the regex here is `'<invention-title.*?>(.*?)</invention-title>'` \n",
    ".The first group is patent title\n",
    "\n",
    "### *Number of claims:*\n",
    "The number of claims located between tag `<number-of-claims>` and `</number-of-claims>`\n",
    "\n",
    "for example: `<number-of-claims>18</number-of-claims>`\n",
    "\n",
    "To extract this number, we use re.search method with regex `r'<number-of-claims>(\\d*?)</number-of-claims>'` and then .group(1)\n",
    "to take number between 2 tag `<number-of-claims>` and `</number-of-claims>`\n",
    "\n",
    "### *Citations by applicant,examiner:*\n",
    "To counting number of citaions made by applicant and examiner, we need to find all citations and then we will define which is made by applicant or examiner. So each citation will begin from tag `<patcit..>` or `<nplcit..>` and finish at next `</category>` tag. For example,\n",
    "\n",
    "`<patcit num=\"00007\">\n",
    "<document-id>\n",
    "<country>US</country>\n",
    "<doc-number>2013/0053042</doc-number>\n",
    "<kind>A1</kind>\n",
    "<name>Tanikawa</name>\n",
    "<date>20130200</date>\n",
    "</document-id>\n",
    "</patcit>\n",
    "<category>cited by examiner</category>`\n",
    "\n",
    "\n",
    "**OR** \n",
    "\n",
    "\n",
    "`<nplcit num=\"00022\">\n",
    "<othercit>Korean Intellectual Property Office Application No. 10-2016-7024846, Office Action dated May 23, 2017, 5 pages.</othercit>\n",
    "</nplcit>\n",
    "<category>cited by applicant</category>\n",
    "</us-citation>\n",
    "<us-citation>\n",
    "<nplcit num=\"00023\">\n",
    "<othercit>Korean Intellectual Property Office Application No. 10-2016-7024846, Final Office Action dated Nov. 10, 2017, 5 pages.</othercit>\n",
    "</nplcit>\n",
    "<category>cited by applicant</category>`\n",
    "\n",
    "For each citation, it ends with a information about `cited by applicant` or `cited by examiner`. So our approach is that we use re.findall() method to find all citations first.Secondly, for each citation, if it has a string `cited by applicant` we count it for element  citation_count_applicant. Otherwise, if a string `cited by examiner` placed on citation we count it for element citation citation_count_examiner\n",
    "Regex here is: `r'<patcit[\\s\\S]*?</category>|<nplcit[\\s\\S]*?</category>'`\n",
    "### *Inventors*\n",
    "All information of inventors placed between `<inventors>` and `</inventors>`. For each inventor, information begin from `<inventor..>` ending with `</inventor>`. For example,\n",
    "`<inventor sequence=\"002\" designation=\"us-only\"> <addressbook> <last-name>Seo</last-name> <first-name>Hanbyul</first-name> <address> <city>Seoul</city> <country>KR</country> </address> </addressbook> </inventor>`\n",
    "\n",
    "Last name locate between `<last-name>`,`</last-name>` and first name place between `<first-name>`,`</first-name>`.  \n",
    "Firstly, we extract data from `<inventors>` to `</inventors>` by re.search method with regex `r'<inventors[\\s\\S]*?</inventors>'` . Similarly, using re.findall method with regex `r'<inventor[\\s\\S]*?</inventor>'` on data we extract from the first step, we get a list of string that contains first name and last name of inventors. To obtain those information, we use re.search method `(r\"<last-name>(.*?)</last-name>\")` and `(r\"<first-name>(.*?)</first-name>\")`. After that, we concentrate two of them and put it on a list of inventors \n",
    "\n",
    "\n",
    "### *Kind*:\n",
    "The kind of patent document be categoized according to the [kind codes](https://www.uspto.gov/learning-and-resources/support-centers/electronic-business-center/kind-codes-included-uspto-patent). \n",
    "The information of patents kind lie in between tag `<publication-reference>` and `</publication-reference>` then kind code itself can be found between `<kind>` and `</kind>`\n",
    "\n",
    "for example:\n",
    "\n",
    "`<publication-reference>\n",
    "<document-id>\n",
    "<country>US</country>\n",
    "<doc-number>10362598</doc-number>\n",
    "<kind>B2</kind>\n",
    "<date>20190723</date>\n",
    "</document-id>\n",
    "</publication-reference>`\n",
    "\n",
    "To extract this kind code and translate into the right group description, we need re.search method with regex `r'<publication-reference>([\\s\\S]*?)</publication-reference>'` and then `.group(1)` to match the information of patents kind.\n",
    "In addition, use re.search method with regex `r'<kind>([\\s\\S]*?)</kind>'` and `.group(1)` again to capture the kinds code, after that match the derived kind code with the rigth group description as shown below.\n",
    "\n",
    "<img src = \"Capture.png\" height = \"600\" width = \"500\">\n",
    "\n",
    "\n",
    "### *Claim text:*\n",
    "The claims information is located between tag `<claim-text>` and `</claim-text>`.\n",
    "In the whole claims information, there could be one or more claim text of each claim depending on the number of claim in that particular patent. \n",
    "We start with extract the whole claims text using re.findall to capture the claims information which begins with `<claim id=\"CLM-00001\" num=\"00001\">` and end with `</claims>` then we remove all of unnecesary character for instance, white space, new line and other claims number in the blanket using regex re.sub.\n",
    "\n",
    "for example: \n",
    "\n",
    "`<claim id=\"CLM-00001\" num=\"00001\">\n",
    "<claim-text>The ornamental design for a weighted golf club grip, as shown and described.</claim-text>\n",
    "</claim>\n",
    "</claims>`\n",
    "\n",
    "The regex that we use to capture this `<claim\\sid=\".+\">([\\s\\S]+?)<\\/claims>` and to remove all the thing we use regex re.sub with `r'<[^>]*>|\\'|\\\"|\\\\n'` and `r'\\s{2,}'`\n",
    "\n",
    "In the case that there is no claims text, re.findall will return empty set `[]`. Therefore we add another line of code for empty set to become `\"NA\"`\n",
    "  \n",
    "\n",
    "### *Abstract:*\n",
    "The abstract of the patents is located between tag `<abstract id=\"abstract\">` and `</abstract>`\n",
    "To extract the information between the tag, we use regex re.search with `<abstract[\\s\\S]+?<p.+?>(.+)?<\\/abstract>` to match the pattern of the abstract and remove inside-text tag using re.sub `r'<.+?>|\\s{2,}'` since there are some tags and white space there.\n",
    "\n",
    "for example:\n",
    "\n",
    "`<abstract id=\"abstract\">\\n<p id=\"p-0001\" num=\"0000\">This invention discloses a novel system and method for distributing electronic ticketing to mobile devices such that the ticket stored on the device is checked for its integrity from tampering and the device periodically reports on ticket usage with a central server.</p>\\n</abstract>`\n",
    "\n",
    "In the case that no abstract is found, we set it to `\"NA\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Transform data into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert the list of data into dataframe \n",
    "df=pd.DataFrame(data,columns=[\"grant_id\",\"patent_kind\",\"kind\",'number_of_claims',\"inventors\",'citations_applicant_count',\"citations_examiner_count\",\"claims_text\",\"abstract\"])\n",
    "#convert dataframe into .csv file\n",
    "df.to_csv(\"Group148.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to transform all extracted data into `.csv` file, we need to put our data which is currently in a list into dataframe after that use the function of pandas package function `.to_csv` to turn dataframe into the `.csv` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Transform data into json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all unnecessary white spaces\n",
    "str1=str(dict1).replace(\": \",\":\").replace(\", \\'\",\",\\'\")\n",
    "# change all single quote to double quote\n",
    "replacement=[(\"{\\'\",\"{\\\"\"),(\"\\'}\",\"\\\"}\"),(\"\\':\",\"\\\":\"),(\":\\'\",\":\\\"\"),(\"\\',\",\"\\\",\"),(\",\\'\",\",\\\"\")]\n",
    "for old,new in replacement:\n",
    "    str1=re.sub(old,new,str1)\n",
    "# write a txt file with json format\n",
    "with open('Group148.json','w',encoding='utf-8') as outfile:\n",
    "    outfile.write(str1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step here is remove all unnecessary white space since from json format ther is no white space next to character `:` which located between key-value pairs and also there is no space between items.\n",
    "\n",
    "\n",
    "Secondly, in json file, each key and value enclosed by double quotes not single quotes. Hence, the next step is changing all heading and trailing single quote of every key and value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "This assessment measured the understanding of basic text file processing techniques in the Python programming language. The main outcomes achieved while applying these techniques were:\n",
    "\n",
    "- **XML parsing and data extraction**. By using the built-in package called `re` or Regex module. With functions like `findall()` ,`search()` and `sub()`, allow us to spot all the pattern of data with only a few inspections inluding replace unecessary characters in a proper way.\n",
    "- **Data frame manipulation**. By using the `pandas` package, we can import the list into data frames straightforward and it is simple to do when adding and arranging all the columns' name.\n",
    "- **Exporting data to specific format**. By using built-in functions like `DataFrame.to_csv()` it is possible to export data frames into `.csv` file without additional formatting and transformations. Exporting data into `.json` file without using `json` package is quite challanging. All we need to do is import data into dictiony and arrange everything according to the right format and export it as output file rightaway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Reference\n",
    "\n",
    "- Regular Expression HOWTO — Python 3.7.4 documentation. (2019). Retrieved 22 August 2019, from https://docs.python.org/3/howto/regex.html\n",
    "- Efficient way of matching and replacing multiple strings in python 3?. (2019). Retrieved 22 August 2019, from https://stackoverflow.com/questions/44528197/efficient-way-of-matching-and-replacing-multiple-strings-in-python-3?fbclid=IwAR2RI5myx3NKrRoB_ZhUL45yAQc8sZ54Yp_MPZZw5MefcYLMtv15jBgnqo4\n",
    "- pandas.DataFrame.to_csv — pandas 0.25.0 documentation. (2019). Retrieved 22 August 2019, from https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
    "- Dib, F. (2019). Online regex tester and debugger: PHP, PCRE, Python, Golang and JavaScript. Retrieved 22 August 2019, from https://regex101.com\n",
    "- JSON Formatter & Validator. (2019). Retrieved 22 August 2019, from https://jsonformatter.curiousconcept.com/?fbclid=IwAR3uOy87IPaE0oZWQeFHScBOOBMn8kwYNiTShTqVIKpan1jmOjLI5UzeiD8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
